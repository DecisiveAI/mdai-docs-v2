+++
title = 'Create a Pipeline for Log Data'
weight = 30
+++

As they run, services generate log data to provide visibility into what's happening. Log data can include anything from benign informational messages to full-blown errors. You want to know about errors, but too many informational messages can become distracting noise.

You'll be able to use MDAI to filter out unnecessary log lines. First lets set up log generators and a pipeline to collect the logs and display telemetry data.

## Generate Log Data

Let's create 3 different log generators. The first emits logs for random services named `service####`, where `####` is a random number.

```
kubectl apply -f ./example_log_generator.yaml
```

The second is a noisy log generator for a particular service (`service1234` by default).

```
kubectl apply -f ./example_log_generator_noisy_service.yaml
```

The third is an excessively noisy version of the second log generator, but for a different service (`service4321` by default).

```
kubectl apply -f ./example_log_generator_xtra_noisy_service.yaml
```

### Verify That Logs Are Being Generated

If the log generators are running, get the pods.

```
kubectl get pods -n mdai -l app.kubernetes.io/part-of=mdai-log-generator
```

Verify that logs are being generated by using the `kubectl logs` command with any one of the pods.

```
kubectl logs -n mdai xtra-noisy-logz-{replace with pod hash}
```

For examlpe, the logs from the pod named **xtra-noisy-logz-54c7877c4f-5svx8** should contain a variety of log levels.

```
2025-02-06T04:43:50+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:50+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:50+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:50+00:00 - service4321 - ERROR - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:50+00:00 - service4321 - ERROR - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:50+00:00 - service4321 - WARNING - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - ERROR - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - WARNING - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - WARNING - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - WARNING - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - WARNING - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - ERROR - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - ERROR - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
2025-02-06T04:43:51+00:00 - service4321 - INFO - The algorithm successfully executed, triggering neural pathways and producing a burst of optimized data streams.
```

> [!TIP]
> You can instead use K9s for obverving the logs. To launch the K9s application, enter `k9s` in the terminal window where you launched the cluster (for the correct context). Use the arrow keys to select one of the log generators, then press **l** (lowercase letter l). Press ESC to the log window.

## Set Up a Collector

We have created a couple examples for the [**MDAI Custom Resource Config**](../usages/configs/mdai_custom_resource_config.md) and [**MDAI OpenTelemetry Collector Sample Config**](../usages/configs/otel_collector_sample_config.md) on our [**Configs repo**](https://github.com/DecisiveAI/configs). You can also checkout our [**configs docs**](../usages/configs/_index.md) for more info on setting up your configurations. Add your configs to the files directory of **mdai-helm-chart repo**

1. From the **mdai-helm-chart repo's root directory**, install your collector with your [**OpenTelemetry Collector Sample Config**](../usages/configs/otel_collector_sample_config.md). If you'd like to use our sample configuration, you can download the [**MDAI OpenTelemetry Collector Sample Config**](https://github.com/DecisiveAI/configs/blob/main/mdai_v1_opentelemetry_collector_sample_config_0_6_0.yaml) and add to file directory of **mdai-helm-chart repo**.

```
kubectl apply -f ./files/mdai_v1_opentelemetry_collector_sample_config_0_6_0.yaml
```
2. From the **mdai-helm-chart repo's root directory**, install your collector with your [**MDAI Custom Resource Config**](../usages/configs/mdai_custom_resource_config.md). If you'd like to use our sample configuration, you can download the [**MDAI Custom Resource Config**](https://github.com/DecisiveAI/configs/blob/main/mdai_v1_mdaihub_sample_config_0_6_0.yaml) and add to file directory of **mdai-helm-chart repo**.

```
kubectl apply -f ./files/mdai_v1_mdaihub_sample_config_0_6_0.yaml
```

Verify that the collector is running in Kubernetes.

```
kubectl -o wide -n mdai get pods --selector app.kubernetes.io/name=gateway-collector
```

## Collect Logs

Use Fluentd to get the logs from where they're being produced to the collector.

1. Install Fluentd.
    ```
    helm upgrade --install --repo https://fluent.github.io/helm-charts fluent fluentd -f values_fluentd.yaml
    ```
2. Confirm that Fluentd is running in the default name spce.
     ```
     kubectl get pods
     ```
    This also gives you the name of the Fluentd pod.
3. Look at the Fluentd logs, which should indicate that various pod log files are being accessed.
    ```
     kubectl logs fluent-fluentd-hrxt4
    ```
    You should see log lines similar to the following.
    ```
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/mdai-prometheus-node-exporter-957tk_mdai_node-exporter-5b9ba8e8394e00b48b54534c075097cdc1bff99d2e634684d450645062a3a390.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/mdai-prometheus-node-exporter-957tk_mdai_node-exporter-f6b7eacef004e60992050358d14a1e0780fa56c5cab236b66dcc4aa8debf7ecd.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-6wmrb_mdai_noisy-mclogface-c60bf1edeacfca17682f7bdb87213485ec4ec18571b334c5953ba74b25dda802.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-6wmrb_mdai_noisy-mclogface-c85adcb072728b92991a967a4e7503c88e4be5ce0e9d324e10cb56d67065a6fd.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-7x4qd_mdai_noisy-mclogface-3d159b3e51d63dae5686122bfa03e21fd3f5faf99ae5563b588bbaaeab50d2d1.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-7x4qd_mdai_noisy-mclogface-b343a4e7d4e995249a934119898368dc11a827a695fb8cb20309dbe67a50a7b9.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-fwnxk_mdai_noisy-mclogface-609ac69e83dd09e70948f3ad19439132246c2b4ee8072f7a21b845224b0aee00.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/noisy-mclogface-7ccd56984f-fwnxk_mdai_noisy-mclogface-ff2407b2005ed2f2f00157840743748800c78078343846acdf0b8539518632d6.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/opentelemetry-operator-57bd64b65d-mnf5d_mdai_manager-e1d482d5de3054b584edf8aee1501856d5fe0b61f3c80626c539c5435c48f7f3.log
    2025-02-10 01:41:18 +0000 [info]: #0 following tail of /var/log/containers/prometheus-kube-prometheus-stack-prometheus-0_mdai_config-reloader-3f50b71d40173e561f5c2110c9ec00241e2057768a4ec6f5267e88589efc6812.log
    ```
